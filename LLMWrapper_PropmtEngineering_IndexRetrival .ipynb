{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6acf8d26",
   "metadata": {},
   "source": [
    "# Used Libraries: \n",
    "/langchain /transformers /torch /pandas /openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a76fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m7mds\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e47c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert LeetSpeak to regular Arabic text\n",
    "def leetspeak_to_arabic(text, leetspeak_dict):\n",
    "    for leet, arabic in leetspeak_dict.items():\n",
    "        text = text.replace(leet, arabic)\n",
    "    return text\n",
    "\n",
    "# Load the lexicon data\n",
    "lexicon_path = \"processed_lexioms.xlsx\"\n",
    "try:\n",
    "    lexicon_data = pd.read_excel(lexicon_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Lexicon file '{lexicon_path}' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Create a dictionary from the lexicon dataframe\n",
    "lexicon_dict = pd.Series(lexicon_data['Term'].values, index=lexicon_data['Term_leetspeak']).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cf3c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: text_column, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Load text data from .xlsx file\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        return df['text_column']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file '{file_path}' not found.\")\n",
    "        create_data_file(file_path)\n",
    "        print(f\"A new file '{file_path}' has been created. Please fill in the 'text_column' and rerun the script.\")\n",
    "        exit()\n",
    "\n",
    "def create_data_file(file_path):\n",
    "    df = pd.DataFrame(columns=['text_column'])\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "# Example usage\n",
    "file_path = 'data.xlsx'\n",
    "data = load_data(file_path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213642ee",
   "metadata": {},
   "source": [
    "# Define the LLM wrappers for Command R+ and AraBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9179977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommandRPlusLLM:\n",
    "    def __init__(self, model_name):\n",
    "        try:\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.pipeline = pipeline('text-classification', model=self.model, tokenizer=self.tokenizer)\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing Command R+ LLM: {e}\")\n",
    "            exit()\n",
    "\n",
    "    def __call__(self, text):\n",
    "        return self.pipeline(text)\n",
    "\n",
    "class AraBERTLLM:\n",
    "    def __init__(self, model_name):\n",
    "        try:\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.pipeline = pipeline('text-classification', model=self.model, tokenizer=self.tokenizer)\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing AraBERT LLM: {e}\")\n",
    "            exit()\n",
    "\n",
    "    def __call__(self, text):\n",
    "        return self.pipeline(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0814f414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models:\n",
      "bert-base-uncased (Base)\n",
      "bert-large-uncased (Large)\n",
      "distilbert-base-uncased (Base)\n",
      "roberta-base (Base)\n",
      "roberta-large (Large)\n",
      "aubmindlab/bert-base-arabertv02 (Base)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Dictionary of common model names and their sizes\n",
    "common_models = {\n",
    "    \"bert-base-uncased\": \"Base\",\n",
    "    \"bert-large-uncased\": \"Large\",\n",
    "    \"distilbert-base-uncased\": \"Base\",\n",
    "    \"roberta-base\": \"Base\",\n",
    "    \"roberta-large\": \"Large\",\n",
    "    # Add more models as needed\n",
    "    \"aubmindlab/bert-base-arabertv02\": \"Base\",\n",
    "    # Add Command R+ and other models here\n",
    "}\n",
    "\n",
    "print(\"Available Models:\")\n",
    "for model_name, size in common_models.items():\n",
    "    print(f\"{model_name} ({size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fee52a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Specify the model size during initialization\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5567199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize AraBERT\n",
    "try:\n",
    "    arabert = AraBERTLLM('aubmindlab/bert-base-arabertv02')\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing AraBERT LLM: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e762c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Command R+\n",
    "#try:\n",
    "#    command_r_plus = CommandRPlusLLM('path_to_command_r_plus_model')\n",
    "#    arabert = AraBERTLLM('aubmindlab/bert-base-arabertv02')\n",
    "#except Exception as e:\n",
    "#    print(f\"Error initializing models: {e}\")\n",
    "#    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1648111",
   "metadata": {},
   "source": [
    "# Define prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c8679a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m7mds\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Define prompt templates for sentiment analysis\n",
    "sentiment_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Analyze the sentiment of the following Arabic text: {text}\"\n",
    ")\n",
    "\n",
    "# Define prompt templates for topic modeling\n",
    "topic_modeling_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Identify the main topics in the following Arabic text: {text}\"\n",
    ")\n",
    "\n",
    "# Create LLMChains for Command R+ to perform sentiment analysis and topic modeling\n",
    "#command_r_plus_sentiment_chain = LLMChain(\n",
    "#    llm=HuggingFacePipeline(pipeline=command_r_plus.pipeline),\n",
    "#    prompt=sentiment_prompt\n",
    "#)\n",
    "\n",
    "#command_r_plus_topic_chain = LLMChain(\n",
    "#    llm=HuggingFacePipeline(pipeline=command_r_plus.pipeline),\n",
    "#    prompt=topic_modeling_prompt\n",
    "#)\n",
    "\n",
    "# Create LLMChains for AraBERT to perform sentiment analysis and topic modeling\n",
    "arabert_sentiment_chain = LLMChain(\n",
    "    llm=HuggingFacePipeline(pipeline=arabert.pipeline),\n",
    "    prompt=sentiment_prompt\n",
    ")\n",
    "\n",
    "arabert_topic_chain = LLMChain(\n",
    "    llm=HuggingFacePipeline(pipeline=arabert.pipeline),\n",
    "    prompt=topic_modeling_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c090bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform sentiment analysis and topic modeling\n",
    "def analyze_text(text):\n",
    "#    command_r_plus_sentiment_result = command_r_plus_sentiment_chain.run({\"text\": text})\n",
    "#    command_r_plus_topic_result = command_r_plus_topic_chain.run({\"text\": text})\n",
    "    \n",
    "    arabert_sentiment_result = arabert_sentiment_chain.run({\"text\": text})\n",
    "    arabert_topic_result = arabert_topic_chain.run({\"text\": text})\n",
    "    \n",
    "    return (arabert_sentiment_result, arabert_topic_result)\n",
    "#    return (command_r_plus_sentiment_result, command_r_plus_topic_result)\n",
    "\n",
    "# Load text data from .xlsx file\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        return df['text_column']  # Adjust column name as necessary\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file '{file_path}' not found.\")\n",
    "        exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a51a862",
   "metadata": {},
   "source": [
    "# Save to .xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e2cec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Load text data from .xlsx file\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        return df['text_column']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file '{file_path}' not found.\")\n",
    "        create_data_file(file_path)\n",
    "        print(f\"A new file '{file_path}' has been created. Please fill in the 'text_column' and rerun the script.\")\n",
    "        exit()\n",
    "\n",
    "def create_data_file(file_path):\n",
    "    df = pd.DataFrame(columns=['text_column'])\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "# function to process the text\n",
    "def leetspeak_to_arabic(text, lexicon_dict):\n",
    "    return text\n",
    "\n",
    "# function to analyze the text\n",
    "def analyze_text(processed_text):\n",
    "\n",
    "    return 'sentiment', 'topic', 'arabert_sentiment', 'arabert_topic'\n",
    "\n",
    "file_path = 'Post_Process_RAW.xlsx'\n",
    "texts = load_data(file_path)\n",
    "\n",
    "if texts is not None:\n",
    "    results = []\n",
    "\n",
    "    for text in texts:\n",
    "        processed_text = leetspeak_to_arabic(text, lexicon_dict)\n",
    "#        command_r_plus_sentiment, command_r_plus_topic,\n",
    "        arabert_sentiment, arabert_topic = analyze_text(processed_text)\n",
    "        \n",
    "        results.append({\n",
    "            'original_text': text,\n",
    "            'processed_text': processed_text,\n",
    "#            'command_r_plus_sentiment': command_r_plus_sentiment,\n",
    "#            'command_r_plus_topic': command_r_plus_topic,\n",
    "            'arabert_sentiment': arabert_sentiment,\n",
    "            'arabert_topic': arabert_topic\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df)\n",
    "\n",
    "    # Save results to a new Excel file\n",
    "    results_df.to_excel('sentiment_topic_analysis_results.xlsx', index=False)\n",
    "else:\n",
    "    print(\"No data to process. Exiting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3290ec",
   "metadata": {},
   "source": [
    "# Indexes for Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb56ae80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "index = {i: results_df.iloc[i].to_dict() for i in range(len(results_df))}\n",
    "\n",
    "def retrieve_by_index(index, idx):\n",
    "    return index.get(idx, None)\n",
    "\n",
    "# Example of retrieving data by index\n",
    "example_idx = 0  # Change the index as needed\n",
    "retrieved_data = retrieve_by_index(index, example_idx)\n",
    "print(retrieved_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
